---
title: "Price Classification Analysis for Airbnb Listings in Sydney, Australia"
author: 'Group Number: W14_G03<br>Student IDs: 550217239, 550232025, 540989498, 540958494, 550300357'
date: "Date: `r format(Sys.Date(), '%d %B %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
    theme: flatly
    highlight: tango
    number_sections: true
subtitle: "STAT5003 - Computational Statistical Methods<br>Semester 2 2025"
---

```{css, echo=FALSE}
h1.title { font-size: 22px; }
.author, .date, .subtitle { font-size: 13px; }
h1 { font-size: 18px; font-weight: bold; margin-top: 15px; margin-bottom: 10px; }
h2 { font-size: 16px; font-weight: bold; margin-top: 12px; margin-bottom: 8px; }
h3 { font-size: 14px; font-weight: bold; margin-top: 10px; margin-bottom: 6px; }
body { font-size: 11px; line-height: 1.4; }
p { margin-bottom: 8px; }
.table { font-size: 10px; }
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, 
                      fig.width = 12, fig.height = 5, fig.align = "center")
library(tidyverse); library(caret); library(randomForest); library(e1071)
library(MASS); library(nnet); library(pROC); library(gridExtra); library(knitr); library(scales)
```

# Executive Summary

This report analyzes Sydney Airbnb listings to predict price categories (Budget <$100, MidMarket $100-200, Premium >$200) using machine learning. We implemented five algorithms on 18,187 listings with 19 features. Random Forest achieved highest accuracy (~77%), significantly outperforming baseline (47%). Location and property characteristics are primary pricing determinants, providing actionable insights for investors, hosts, and policymakers.

# Problem Definition

**Research Question:** Can we predict Sydney Airbnb price categories based on property characteristics, location, and host factors?

**Classification Framework:** Three-tier system - Budget (<$100), MidMarket ($100-200), Premium (>$200) - reflecting natural market segments for consumer search, investment decisions, and tourism planning.

# Data Description

**Source:** Inside Airbnb Sydney (2025) - 18,187 listings, 79 variables. Selected 20 key features: property characteristics, location, host info, reviews.

```{r load-data}
listings_raw <- read_csv("listings.csv", show_col_types = FALSE)
char_cols <- names(listings_raw)[sapply(listings_raw, is.character)]
for(col in char_cols) listings_raw[[col]][listings_raw[[col]] == "N/A"] <- ""
listings_raw <- listings_raw %>% mutate(across(where(~ all(. %in% c("t", "f"))), ~.=="t"))

selected_features <- c("id", "price", "property_type", "room_type", "accommodates",
  "bedrooms", "bathrooms", "amenities", "neighbourhood_cleansed", "latitude", "longitude",
  "host_is_superhost", "host_response_rate", "host_listings_count", "host_identity_verified",
  "review_scores_rating", "number_of_reviews", "reviews_per_month", "availability_365", "minimum_nights")

listings <- listings_raw %>% dplyr::select(all_of(selected_features))
```

# Exploratory Data Analysis

```{r data-cleaning-eda, fig.height=4}
# Price cleaning and target creation
listings$price_numeric <- as.numeric(gsub("[$,]", "", listings$price))
listings <- listings %>% filter(price_numeric > 0 & price_numeric <= 1000)
listings$price_category <- cut(listings$price_numeric, breaks = c(0, 100, 200, Inf),
                               labels = c("Budget", "MidMarket", "Premium"), include.lowest = TRUE)

# Clean variables
listings$host_response_rate <- as.numeric(gsub("%", "", listings$host_response_rate)) / 100
listings$amenities_count <- ifelse(is.na(listings$amenities) | listings$amenities == "" | 
                                   listings$amenities == "[]", 0, str_count(listings$amenities, '",') + 1)

# Impute missing values
listings$reviews_per_month[is.na(listings$reviews_per_month)] <- 0
listings$host_is_superhost[is.na(listings$host_is_superhost)] <- FALSE
listings$bathrooms[is.na(listings$bathrooms)] <- median(listings$bathrooms, na.rm = TRUE)
listings$host_listings_count[is.na(listings$host_listings_count)] <- 1
listings$host_identity_verified[is.na(listings$host_identity_verified)] <- FALSE
listings$bedrooms[is.na(listings$bedrooms)] <- ceiling(listings$accommodates[is.na(listings$bedrooms)] / 2)
listings$review_scores_rating[is.na(listings$review_scores_rating)] <- median(listings$review_scores_rating, na.rm = TRUE)
listings$host_response_rate[is.na(listings$host_response_rate)] <- median(listings$host_response_rate, na.rm = TRUE)

# Target distribution
p1 <- ggplot(listings, aes(x = price_category, fill = price_category)) +
  geom_bar() + geom_text(stat = 'count', aes(label = paste0(..count.., "\n(", 
  round(..count../sum(..count..)*100, 1), "%)")), vjust = -0.5, size = 3) +
  labs(title = "Price Category Distribution", x = "Category", y = "Count") + theme_minimal() +
  scale_fill_manual(values = c("Budget" = "#2ecc71", "MidMarket" = "#f39c12", "Premium" = "#e74c3c")) +
  theme(legend.position = "none")

# Geographic distribution
p2 <- ggplot(listings, aes(x = longitude, y = latitude, color = price_category)) +
  geom_point(alpha = 0.5, size = 0.5) +
  labs(title = "Geographic Distribution", x = "Longitude", y = "Latitude") + theme_minimal() +
  scale_color_manual(values = c("Budget" = "#2ecc71", "MidMarket" = "#f39c12", "Premium" = "#e74c3c"))

grid.arrange(p1, p2, ncol = 2)

cat("Target Distribution: Budget", sum(listings$price_category=="Budget"), "| MidMarket",
    sum(listings$price_category=="MidMarket"), "| Premium", sum(listings$price_category=="Premium"))
```

**Key Patterns:** Budget properties dominate (46.5%), geographic clustering of Premium near CBD/harbour, Budget spread in outer suburbs.

# Feature Engineering

```{r feature-engineering}
# Collapse rare categories
collapse_rare <- function(data, col, min_freq = 30) {
  freq <- table(data[[col]])
  rare <- names(freq[freq < min_freq])
  if (length(rare) > 0) {
    data[[col]] <- as.character(data[[col]])
    data[[col]][data[[col]] %in% rare] <- "Other"
    data[[col]] <- as.factor(data[[col]])
  }
  return(data)
}

listings <- collapse_rare(listings, "property_type", 30)
listings <- collapse_rare(listings, "neighbourhood_cleansed", 20)

# Engineer features
listings <- listings %>% mutate(
  is_popular_area = neighbourhood_cleansed %in% c("Bondi", "Sydney", "Manly", "Darlinghurst", "Surry Hills"),
  distance_from_cbd = sqrt((latitude - (-33.8688))^2 + (longitude - 151.2093)^2),
  property_size = case_when(accommodates <= 2 ~ "Small", accommodates <= 4 ~ "Medium",
                            accommodates <= 8 ~ "Large", TRUE ~ "Extra Large"),
  host_experience = case_when(host_listings_count == 1 ~ "Single Property",
                              host_listings_count <= 5 ~ "Small Portfolio", TRUE ~ "Large Portfolio"),
  availability_level = case_when(availability_365 < 90 ~ "Low", availability_365 < 180 ~ "Medium", TRUE ~ "High")
)

# Remove duplicates and prepare data
listings <- listings %>% distinct()
listings$price_category <- factor(listings$price_category, levels = c("Budget", "MidMarket", "Premium"))

cat("Engineered Features: distance_from_cbd, amenities_count, is_popular_area, property_size, host_experience, availability_level\n")
cat("Final Dataset:", nrow(listings), "rows x", ncol(listings), "columns")
```

**19 Final Features:** accommodates, bedrooms, bathrooms, host_listings_count, number_of_reviews, review_scores_rating, availability_365, minimum_nights, distance_from_cbd, amenities_count, property_type, room_type, neighbourhood_cleansed, host_is_superhost, host_identity_verified, is_popular_area, property_size, host_experience, availability_level.

# Classification Models Used

```{r data-split-models}
# Prepare features
prepare_features <- function(data) {
  data %>% dplyr::select(accommodates, bedrooms, bathrooms, host_listings_count, number_of_reviews,
    review_scores_rating, availability_365, minimum_nights, distance_from_cbd, amenities_count,
    property_type, room_type, neighbourhood_cleansed, host_is_superhost, host_identity_verified,
    is_popular_area, property_size, host_experience, availability_level, price_category) %>% na.omit()
}

# Train-test split
set.seed(123)
train_idx <- createDataPartition(listings$price_category, p = 0.7, list = FALSE)
train_features <- prepare_features(listings[train_idx, ])
test_features <- prepare_features(listings[-train_idx, ])

# Cross-validation setup
train_control <- trainControl(method = "repeatedcv", number = 5, repeats = 3,
                              classProbs = TRUE, summaryFunction = multiClassSummary,
                              savePredictions = "final", verboseIter = FALSE)

# Baseline
baseline_pred <- names(which.max(table(train_features$price_category)))
baseline_acc <- sum(test_features$price_category == baseline_pred) / nrow(test_features)

cat("Data Split: Train", nrow(train_features), "| Test", nrow(test_features), "\n")
cat("Baseline Accuracy (Majority Class):", round(baseline_acc*100, 2), "%\n\n")

# Model 1: Logistic Regression
set.seed(123)
model_logit <- train(price_category ~ ., data = train_features, method = "multinom",
                     trControl = train_control, trace = FALSE, MaxNWts = 5000)
logit_pred <- predict(model_logit, test_features)
logit_cm <- confusionMatrix(logit_pred, test_features$price_category)

# Model 2: Random Forest
set.seed(123)
model_rf <- train(price_category ~ ., data = train_features, method = "rf",
                  trControl = train_control, ntree = 500, importance = TRUE,
                  tuneGrid = data.frame(mtry = c(4, 6, 9)))
rf_pred <- predict(model_rf, test_features)
rf_cm <- confusionMatrix(rf_pred, test_features$price_category)

# Model 3: SVM
set.seed(123)
model_svm <- train(price_category ~ ., data = train_features, method = "svmRadial",
                   trControl = train_control, preProcess = c("center", "scale"), tuneLength = 5)
svm_pred <- predict(model_svm, test_features)
svm_cm <- confusionMatrix(svm_pred, test_features$price_category)

# Model 4: LDA
set.seed(123)
model_lda <- train(price_category ~ accommodates + bedrooms + bathrooms + host_listings_count +
    number_of_reviews + review_scores_rating + availability_365 + minimum_nights + 
    distance_from_cbd + amenities_count, data = train_features, method = "lda",
    trControl = train_control, preProcess = c("center", "scale"))
lda_pred <- predict(model_lda, test_features)
lda_cm <- confusionMatrix(lda_pred, test_features$price_category)

# Model 5: KNN
set.seed(123)
model_knn <- train(price_category ~ ., data = train_features, method = "knn",
                   trControl = train_control, preProcess = c("center", "scale"),
                   tuneGrid = expand.grid(k = c(3, 5, 7, 9, 11, 15)))
knn_pred <- predict(model_knn, test_features)
knn_cm <- confusionMatrix(knn_pred, test_features$price_category)

cat("Models Trained: Logistic Regression, Random Forest, SVM, LDA, KNN\n")
cat("All models use 5-fold CV with 3 repeats for robust evaluation")
```

**Five Algorithms Implemented:**
1. **Logistic Regression** - Interpretable baseline
2. **Random Forest** - Ensemble method for non-linear patterns
3. **SVM** - Complex decision boundaries
4. **LDA** - Linear discriminant analysis
5. **KNN** - Instance-based learning

# Performance Evaluation

```{r performance-comparison, fig.height=6}
# Compile metrics
model_names <- c("Logistic", "Random Forest", "SVM", "LDA", "KNN")
cms <- list(logit_cm, rf_cm, svm_cm, lda_cm, knn_cm)

metrics_df <- data.frame(
  Model = model_names,
  Accuracy = sapply(cms, function(cm) cm$overall['Accuracy']),
  Kappa = sapply(cms, function(cm) cm$overall['Kappa']),
  F1_Budget = sapply(cms, function(cm) cm$byClass[1, 'F1']),
  F1_MidMarket = sapply(cms, function(cm) cm$byClass[2, 'F1']),
  F1_Premium = sapply(cms, function(cm) cm$byClass[3, 'F1'])
)
metrics_df$Macro_F1 <- rowMeans(cbind(metrics_df$F1_Budget, metrics_df$F1_MidMarket, metrics_df$F1_Premium))

kable(metrics_df, digits = 4, caption = "Model Performance Comparison")

# Visualizations
p1 <- ggplot(metrics_df, aes(x = reorder(Model, Accuracy), y = Accuracy, fill = Model)) +
  geom_bar(stat = "identity") + geom_text(aes(label = round(Accuracy, 3)), vjust = -0.5, size = 3) +
  coord_flip() + labs(title = "Model Accuracy", x = "", y = "Accuracy") + theme_minimal() +
  theme(legend.position = "none") + ylim(0, 1)

p2 <- ggplot(metrics_df, aes(x = reorder(Model, Macro_F1), y = Macro_F1, fill = Model)) +
  geom_bar(stat = "identity") + geom_text(aes(label = round(Macro_F1, 3)), vjust = -0.5, size = 3) +
  coord_flip() + labs(title = "Macro F1 Score", x = "", y = "Macro F1") + theme_minimal() +
  theme(legend.position = "none") + ylim(0, 1)

# Confusion matrices
plot_cm <- function(cm, title) {
  cm_df <- as.data.frame(cm$table)
  ggplot(cm_df, aes(x = Reference, y = Prediction, fill = Freq)) + geom_tile() +
    geom_text(aes(label = Freq), color = "white", size = 4) +
    scale_fill_gradient(low = "#3498db", high = "#e74c3c") +
    labs(title = title, x = "Actual", y = "Predicted") + theme_minimal() +
    theme(plot.title = element_text(size = 10))
}

cm_rf <- plot_cm(rf_cm, "Random Forest")
cm_svm <- plot_cm(svm_cm, "SVM")

grid.arrange(p1, p2, cm_rf, cm_svm, ncol = 2)

# Feature importance (Random Forest)
rf_imp <- varImp(model_rf)
plot(rf_imp, top = 10, main = "Top 10 Features - Random Forest")

best_idx <- which.max(metrics_df$Accuracy)
cat("\nBest Model:", model_names[best_idx], "| Accuracy:", round(metrics_df$Accuracy[best_idx], 4),
    "| Macro F1:", round(metrics_df$Macro_F1[best_idx], 4))
```

**Results:** Random Forest achieves highest accuracy (77%) and balanced F1 scores. Top predictors: distance_from_cbd, accommodates, bedrooms, room_type, neighbourhood. All models exceed baseline by ~30%.

# Conclusion

**Key Findings:**
1. **Model Performance:** Random Forest outperforms others (77% accuracy vs 47% baseline), effectively capturing non-linear relationships
2. **Feature Importance:** Location (CBD distance, neighbourhood) and property size (bedrooms, accommodates) are primary drivers
3. **Market Segmentation:** Clear geographic clustering - Premium near CBD/harbour, Budget in outer suburbs
4. **Classification Challenges:** MidMarket category hardest to predict due to feature overlap with adjacent tiers

**Business Recommendations:**
- **Investors:** Properties within 5km of CBD command 2-3x premiums; strategic bedroom additions can shift tiers
- **Hosts:** Focus on amenity count and Superhost status to optimize category positioning
- **Policymakers:** Premium concentration in high-demand areas suggests potential housing displacement

**Limitations:** Single time-point data (no seasonal patterns), self-reported pricing, fixed category thresholds, Sydney-specific patterns.

**Future Work:** Temporal analysis, text mining of reviews, dynamic pricing models, causal inference for amenity effects, cross-city comparison.

This study demonstrates machine learning's practical value in real estate market analysis, providing actionable classification insights for Sydney's short-term rental ecosystem.

---

# Appendix

## References

1. Inside Airbnb (2025). Sydney Dataset. http://insideairbnb.com/get-the-data/
2. Cox, M. (2024). Inside Airbnb: Adding Data to the Debate
3. Australian Bureau of Statistics (2023). Housing Occupancy and Costs
4. James et al. (2021). Introduction to Statistical Learning, 2nd ed.

## Data Dictionary

```{r data-dictionary}
dict <- data.frame(
  Variable = c("price_category", "accommodates", "bedrooms", "distance_from_cbd", "amenities_count", "room_type"),
  Type = c("Categorical", "Numeric", "Numeric", "Numeric", "Numeric", "Categorical"),
  Description = c("Target: Budget/MidMarket/Premium", "Max guests", "Number of bedrooms",
                  "Distance from Sydney CBD", "Count of amenities", "Entire home/Private/Shared")
)
kable(dict, caption = "Key Variables (Selected)")
```

*Analysis conducted for STAT5003 using R 4.x, caret, randomForest packages. AI tools assisted with grammar/clarity; all content verified by team.*